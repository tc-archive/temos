{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Vector Operations and Dot Product\n",
    "\n",
    "The __weighted sum__ of two vectors is also known as the __dot product__. It is composed from an  __elementwise_multiplication__ operation followed by a __vector_sum__ operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elementwise_multiplication(vec_a, vec_b):\n",
    "    assert(len(vec_a) == len(vec_b))\n",
    "    result = []\n",
    "    for idx in range(len(vec_a)):\n",
    "        result.append(vec_a[idx] * vec_b[idx])\n",
    "    return result\n",
    "    \n",
    "def vector_sum(vec_a):\n",
    "    result = 0\n",
    "    for a in vec_a:\n",
    "        result += a\n",
    "    return result\n",
    "\n",
    "def dot_product(vec_a, vec_b):\n",
    "    return vector_sum(elementwise_multiplication(vec_a, vec_b))\n",
    "\n",
    "def weighted_sum(inputs, weights):\n",
    "    assert(len(inputs) == len(weights))\n",
    "    prediction = 0\n",
    "    for idx in range(len(weights)):\n",
    "        prediction += inputs[idx] * weights[idx]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elementwise_multiplication [1, 2, 3] [4, 5, 6]   = [4, 10, 18]\n",
      "vector_sum                           [4, 10, 18] = 32\n",
      "--------------------------------------------------------------\n",
      "=> dot_product             [1, 2, 3] [4, 5, 6]   = 32\n",
      "=> weighted_sum            [1, 2, 3] [4, 5, 6]   = 32\n"
     ]
    }
   ],
   "source": [
    "vec_a = [1, 2, 3]\n",
    "vec_b = [4, 5, 6]\n",
    "\n",
    "ewm = elementwise_multiplication(vec_a, vec_b)\n",
    "print(\"elementwise_multiplication {} {}   = {}\".format(vec_a, vec_b, ewm))\n",
    "                     \n",
    "vs = vector_sum(ewm)\n",
    "print(\"vector_sum                           {} = {}\".format(ewm, vs))\n",
    "\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n",
    "dp = dot_product(vec_a, vec_b)\n",
    "print(\"=> dot_product             {} {}   = {}\".format(vec_a, vec_b, dp))\n",
    "\n",
    "ws = weighted_sum(vec_a, vec_b)\n",
    "print(\"=> weighted_sum            {} {}   = {}\".format(vec_a, vec_b, ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dot Product - Logical Intutition\n",
    "\n",
    "A dot product gives us a _notion of similarity_ between two vectors. \n",
    "\n",
    "Rougly speaking, __a neuron gives a high score to an input based on how similar it is to the neuron weights__. If inputs align with weights then they will increase the magnitude of the dot product. If both input and weight have a negative cardinality then they still produce a positive contribution to the final dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot_product i1: [0, 1, 0, 1]\n",
      "            w1: [0, 1, 0, 1]\n",
      "            =   2\n",
      "\n",
      "dot_product i1: [0, 1, 0, 1]\n",
      "            w2: [1, 0, 1, 0]\n",
      "            =   0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i1 = [ 0, 1, 0, 1]\n",
    "w1 = [ 0, 1, 0, 1]\n",
    "w2 = [ 1, 0, 1, 0]\n",
    "\n",
    "print(\"dot_product i1: {}\".format(i1))\n",
    "print(\"            w1: {}\".format(w1))\n",
    "print(\"            =   {}\".format(dot_product(i1, w1)))      \n",
    "print(\"\")\n",
    "print(\"dot_product i1: {}\".format(i1))\n",
    "print(\"            w2: {}\".format(w2))\n",
    "print(\"            =   {}\".format(dot_product(i1, w2)))      \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rougly speaking, with regard to the dot product, the weights in a network can be read with a logical interpretation. The 'elementwise_multiplication' operation is similar to a __logical and__ operation; the 'vector_sum' operation is similar to a __logical or__ operation, and, negative weights (without aligning negative inputs) are similar to a __logical not__ operation. However, the cardinality of the weights and the input also have an effect on the resulting dot product. For example:\n",
    "\n",
    "__[ 1  , 0, 1  ]__ => if input[0] OR input[2]\n",
    "\n",
    "__[ 0  , 0, 1  ]__ => if input[2]\n",
    "\n",
    "__[ 1  , 0, -1 ]__ => if input[0] OR NOT input[2] \n",
    "\n",
    "__[ -1 , 0, -1 ]__ => if NOT input[0] OR NOT input[2] \n",
    "\n",
    "__[ 0.5, 0, 1  ]__ => if BIG input[0] or input[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
